{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import utils\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import ciso8601\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"~/Downloads/coronavirus_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = pd.read_csv('../contacts_15meters_30sec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets =  pd.read_csv(path + 'infusr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp(date_string):\n",
    "    ts = ciso8601.parse_datetime(date_string)\n",
    "    return int(time.mktime(ts.timetuple()))\n",
    "START_DATE = get_timestamp(\"2020-04-13T23:59:59.000000\")\n",
    "END_DATE = get_timestamp(\"2020-04-24T23:59:59.000000\")\n",
    "DAY_LENGTH = 86400\n",
    "# уникальные юзеры\n",
    "unique_users = pd.unique(contacts['user1'])\n",
    "# Формируем сетку\n",
    "time_grid = np.arange(START_DATE, END_DATE, DAY_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets.rename(columns={'user_id': 'user2', 'time': 'contact_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_w_targets = contacts.join(targets.set_index('user2'), on='user2', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_learning_grid(dict_, time, user1, user2):\n",
    "    key = user1 + '/' + str(time)\n",
    "    if key not in dict_.keys():\n",
    "        dict_[key] = set()\n",
    "    dict_[key].add(user2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_dict = {}\n",
    "infected_dict = {}\n",
    "for i, row in contacts_w_targets.iterrows():\n",
    "    time_hash = row['time']\n",
    "    time = time_hash*30\n",
    "    user1 = row['user1']\n",
    "    user2 = row['user2']\n",
    "    close_time_elems = time_grid[((time_grid < time + 7*DAY_LENGTH) & (time_grid > time))]\n",
    "    for time_elem in close_time_elems:\n",
    "        add_to_learning_grid(contacts_dict, time_elem, user1, user2)\n",
    "    contact_time = row['contact_time']\n",
    "    if contact_time == contact_time:\n",
    "        close_time_elems_before = time_grid[\n",
    "            ((time < time_grid + 5*DAY_LENGTH) & (time_grid < time))\n",
    "        ]\n",
    "        close_time_elems_after = time_grid[\n",
    "            ((time_grid < time + 3*DAY_LENGTH) & (time_grid > time))\n",
    "        ]\n",
    "        for time_elem in close_time_elems_before:\n",
    "            add_to_learning_grid(infected_dict, time_elem, user1, user2)\n",
    "        for time_elem in close_time_elems_after:\n",
    "            add_to_learning_grid(infected_dict, time_elem, user1, user2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_list = []\n",
    "for time_step in time_grid:\n",
    "    for user in unique_users:\n",
    "        dict_elem = {'user_id': user, 'grid_time': time_step}\n",
    "        key = user + '/' + str(time_step)\n",
    "        if key in contacts_dict.keys():\n",
    "            dict_elem['contacts_num'] = len(contacts_dict[key])\n",
    "        else:\n",
    "            dict_elem['contacts_num']  = 0\n",
    "        if key in infected_dict.keys():\n",
    "            dict_elem['infected_contacts_num'] = len(infected_dict[key])\n",
    "        else:\n",
    "            dict_elem['infected_contacts_num']  = 0\n",
    "        learning_list.append(dict_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data = pd.DataFrame(learning_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2750, 4)"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets =  pd.read_csv(path + 'infusr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data = learning_data.join(targets.set_index('user_id'), on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_target(inf_time, grid_time):\n",
    "    if inf_time == inf_time:\n",
    "        if 0 <= grid_time - inf_time <= 5*DAY_LENGTH:\n",
    "            return 1\n",
    "        if 0 < inf_time - grid_time <= 3*DAY_LENGTH:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data['target'] = learning_data.apply(\n",
    "    lambda x: calc_target(x['time'], x['grid_time']),  axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_p_t(contacts_num):\n",
    "    logsigmoid = nn.LogSigmoid()\n",
    "    return logsigmoid(torch.tensor(contacts_num/8)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data['log_p_t'] = learning_data.apply(\n",
    "    lambda x: calc_p_t(x['contacts_num']),  axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prev_p_t(user_id, grid_time):\n",
    "    prev_time = grid_time - DAY_LENGTH\n",
    "    row = learning_data[(\n",
    "        (learning_data['grid_time'] == prev_time) & \n",
    "        (learning_data['user_id'] == user_id))]\n",
    "    if row.shape[0] > 0:\n",
    "        return row['log_p_t'].item()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data['prev_log_p_t'] = learning_data.apply(\n",
    "    lambda x: calc_prev_p_t(x['user_id'], x['grid_time']),  axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = learning_data[[el for el in learning_data.columns if el != 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "features, learning_data['target'], test_size=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data_new = x_train.copy()\n",
    "learning_data_new['target'] =y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data_new = learning_data_new[\n",
    "    ((learning_data_new['contacts_num'] > 0) | (learning_data_new['target'] == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1150, 8)"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "learning_data_new = shuffle(learning_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_batches(batch_size, dataset):\n",
    "    datast_size = dataset.shape[0]\n",
    "    step = np.arange(0, datast_size, batch_size)\n",
    "    for i in range(1, len(step)):\n",
    "        slice_ = dataset.iloc[step[i-1]:step[i]]\n",
    "        yield torch.FloatTensor(slice_[['contacts_num', 'infected_contacts_num' ]\n",
    "        ].values), torch.FloatTensor(slice_['prev_log_p_t'].values),torch.LongTensor(\n",
    "            slice_['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogReg, self).__init__()\n",
    "        self.register_parameter(name='bias',\n",
    "                                param=torch.nn.Parameter(torch.randn(1, 1)))\n",
    "        self.register_parameter(name='weight', param=torch.nn.Parameter(\n",
    "            torch.randn(input_dim, 1)))\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "\n",
    "    def forward(self, input_, logp):\n",
    "        weight = torch.exp(self.weight)\n",
    "        bias = torch.exp(self.bias)\n",
    "        out = input_.matmul(weight) - bias + logp.unsqueeze(1)\n",
    "        out_positive = self.logsigmoid(out)\n",
    "        out_negative = self.logsigmoid(out) - out\n",
    "\n",
    "        return torch.cat([out_negative, out_positive], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, weight):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.weight = weight.unsqueeze(0)\n",
    "\n",
    "    def forward(self, input_, target):\n",
    "        target = target.unsqueeze(1)\n",
    "        targets = torch.cat([target, 1 - target], dim=1).float()\n",
    "        return (-input_ * targets*self.weight).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LogReg(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.5300],\n",
       "        [-0.2431]], requires_grad=True)"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = yield_batches(8, learning_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(62.0054, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(8, 2)\n",
    "logp = torch.randn(8)\n",
    "pred = net(y, logp)\n",
    "target = torch.tensor([1, 0 ,1, 0, 1, 0, 1, 0])\n",
    "CustomLoss(weight=torch.FloatTensor([1, 6]))(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalc_log_p(net):\n",
    "    learning_data_old['log_p_t'] = pd.Series(net(\n",
    "        torch.FloatTensor(x_train[['contacts_num', 'infected_contacts_num']].values),\n",
    "        torch.FloatTensor(x_train['prev_log_p_t'].values)\n",
    "    ).detach().numpy()[:, 1])\n",
    "    learning_data_new['prev_log_p_t'] = x_train.apply(\n",
    "    lambda x: calc_prev_p_t(x['user_id'], x['grid_time']),  axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=2\tavg_loss=9.64565\t\n",
      "iteration=5\tavg_loss=6.25140\t\n",
      "iteration=8\tavg_loss=8.21641\t\n",
      "iteration=11\tavg_loss=5.78216\t\n",
      "iteration=14\tavg_loss=5.74387\t\n",
      "iteration=17\tavg_loss=6.48955\t\n",
      "iteration=20\tavg_loss=6.53631\t\n",
      "iteration=23\tavg_loss=5.68565\t\n",
      "iteration=26\tavg_loss=5.26053\t\n",
      "iteration=29\tavg_loss=6.18987\t\n",
      "iteration=32\tavg_loss=6.29299\t\n",
      "iteration=35\tavg_loss=5.96458\t\n",
      "iteration=38\tavg_loss=5.77903\t\n",
      "iteration=41\tavg_loss=5.75628\t\n",
      "iteration=44\tavg_loss=6.09969\t\n",
      "iteration=47\tavg_loss=5.40546\t\n",
      "iteration=50\tavg_loss=5.42493\t\n",
      "iteration=53\tavg_loss=5.76015\t\n",
      "iteration=56\tavg_loss=5.34993\t\n",
      "iteration=59\tavg_loss=7.70770\t\n",
      "iteration=62\tavg_loss=5.48883\t\n",
      "iteration=65\tavg_loss=6.04001\t\n",
      "iteration=68\tavg_loss=5.56634\t\n",
      "iteration=71\tavg_loss=6.99431\t\n",
      "iteration=74\tavg_loss=5.37838\t\n",
      "iteration=77\tavg_loss=6.57014\t\n",
      "iteration=80\tavg_loss=5.65762\t\n",
      "iteration=83\tavg_loss=10.07633\t\n",
      "iteration=86\tavg_loss=6.47464\t\n",
      "iteration=89\tavg_loss=5.78040\t\n",
      "iteration=92\tavg_loss=5.80271\t\n",
      "iteration=95\tavg_loss=5.77408\t\n",
      "iteration=98\tavg_loss=6.14168\t\n",
      "iteration=101\tavg_loss=5.86698\t\n",
      "iteration=104\tavg_loss=5.70597\t\n",
      "iteration=107\tavg_loss=5.61200\t\n",
      "iteration=110\tavg_loss=6.37827\t\n",
      "iteration=113\tavg_loss=6.28112\t\n",
      "iteration=116\tavg_loss=6.63912\t\n",
      "iteration=119\tavg_loss=5.40238\t\n",
      "iteration=122\tavg_loss=5.72674\t\n",
      "iteration=125\tavg_loss=6.03275\t\n",
      "iteration=128\tavg_loss=5.76010\t\n",
      "iteration=131\tavg_loss=6.12985\t\n",
      "iteration=134\tavg_loss=5.03768\t\n",
      "iteration=137\tavg_loss=5.85935\t\n",
      "iteration=140\tavg_loss=5.69376\t\n"
     ]
    }
   ],
   "source": [
    "PRINT_TEMPLATE = (\n",
    "    'iteration={iteration:}\\tavg_loss={avg_loss:.5f}\\t'\n",
    ")\n",
    "\n",
    "net.train()\n",
    "training_logs = []\n",
    "avg_loss = 0\n",
    "learning_rate = 0.05\n",
    "loss_function = CustomLoss(weight=torch.FloatTensor([1, 1]))\n",
    "print_every = 3\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "iteration = 0\n",
    "for  feats, logp, targets in iterator:\n",
    "    optimizer.zero_grad()\n",
    "    predictions = net(feats, logp)\n",
    "    loss = loss_function(predictions, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    avg_loss += loss.item()\n",
    "    recalc_log_p(net)\n",
    "    if iteration % print_every == print_every - 1:\n",
    "        print(PRINT_TEMPLATE.format(\n",
    "            iteration=iteration,\n",
    "            avg_loss=avg_loss/print_every\n",
    "        ))\n",
    "        avg_loss = 0\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_t_test = pd.Series(torch.exp(net(\n",
    "        torch.FloatTensor(x_test[['contacts_num', 'infected_contacts_num']].values),\n",
    "        torch.FloatTensor(x_test['prev_log_p_t'].values)\n",
    "    )).detach().numpy()[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data_old['p_t'] = pd.Series(torch.exp(net(\n",
    "        torch.FloatTensor(learning_data_old[['contacts_num', 'infected_contacts_num']].values),\n",
    "        torch.FloatTensor(learning_data_old['prev_log_p_t'].values)\n",
    "    )).detach().numpy()[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = y_test.values\n",
    "predictions = p_t_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treshold: 0.0 precision: 0.10909090909090909 recall: 1.0\n",
      "treshold: 0.05 precision: 0.10909090909090909 recall: 1.0\n",
      "treshold: 0.1 precision: 0.10909090909090909 recall: 1.0\n",
      "treshold: 0.15000000000000002 precision: 0.10909090909090909 recall: 1.0\n",
      "treshold: 0.2 precision: 0.10909090909090909 recall: 1.0\n",
      "treshold: 0.25 precision: 0.10909090909090909 recall: 1.0\n",
      "treshold: 0.30000000000000004 precision: 0.125 recall: 0.7333333333333333\n",
      "treshold: 0.35000000000000003 precision: 0.12571428571428572 recall: 0.7333333333333333\n",
      "treshold: 0.4 precision: 0.1780821917808219 recall: 0.43333333333333335\n",
      "treshold: 0.45 precision: 0.19047619047619047 recall: 0.4\n",
      "treshold: 0.5 precision: 0.21621621621621623 recall: 0.17777777777777778\n",
      "treshold: 0.55 precision: 0.2 recall: 0.08888888888888889\n",
      "treshold: 0.6000000000000001 precision: 0.1724137931034483 recall: 0.05555555555555555\n",
      "treshold: 0.65 precision: 0.3 recall: 0.03333333333333333\n",
      "treshold: 0.7000000000000001 precision: 0.3333333333333333 recall: 0.03333333333333333\n",
      "treshold: 0.75 precision: 0.3333333333333333 recall: 0.03333333333333333\n",
      "treshold: 0.8 precision: 0.5 recall: 0.03333333333333333\n",
      "treshold: 0.8500000000000001 precision: 0.5 recall: 0.022222222222222223\n",
      "treshold: 0.9 precision: 0.6666666666666666 recall: 0.022222222222222223\n",
      "treshold: 0.9500000000000001 precision: 0.5 recall: 0.011111111111111112\n"
     ]
    }
   ],
   "source": [
    "for treshold in np.arange(0, 1, 0.05):\n",
    "    tp = ((targets == 1) & (predictions > treshold )).sum()\n",
    "    fp = ((targets == 0) & (predictions > treshold)).sum()\n",
    "    tn = ((targets == 0) & (predictions < treshold )).sum()\n",
    "    fn = ((targets == 1) & (predictions < treshold )).sum()\n",
    "    print('treshold:', treshold, 'precision:',  tp/(tp + fp), 'recall:',  tp/(tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv('x_train.csv')\n",
    "y_train.to_csv('y_train.csv')\n",
    "x_test.to_csv('x_test.csv')\n",
    "y_test.to_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3931],\n",
       "        [0.3455]], grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(net.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2439]], grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(net.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treshold: 0.0 precision: 0.1290909090909091 recall: 1.0\n",
      "treshold: 0.05 precision: 0.1290909090909091 recall: 1.0\n",
      "treshold: 0.1 precision: 0.1290909090909091 recall: 1.0\n",
      "treshold: 0.15000000000000002 precision: 0.1290909090909091 recall: 1.0\n",
      "treshold: 0.2 precision: 0.1290909090909091 recall: 1.0\n",
      "treshold: 0.25 precision: 0.1290909090909091 recall: 1.0\n",
      "treshold: 0.30000000000000004 precision: 0.1290909090909091 recall: 1.0\n",
      "treshold: 0.35000000000000003 precision: 0.1290909090909091 recall: 1.0\n",
      "treshold: 0.4 precision: 0.1290909090909091 recall: 1.0\n",
      "treshold: 0.45 precision: 0.1525917297612114 recall: 0.7380281690140845\n",
      "treshold: 0.5 precision: 0.2206148282097649 recall: 0.3436619718309859\n",
      "treshold: 0.55 precision: 0.218562874251497 recall: 0.2056338028169014\n",
      "treshold: 0.6000000000000001 precision: 0.2571428571428571 recall: 0.1267605633802817\n",
      "treshold: 0.65 precision: 0.30357142857142855 recall: 0.04788732394366197\n",
      "treshold: 0.7000000000000001 precision: 0.3611111111111111 recall: 0.036619718309859155\n",
      "treshold: 0.75 precision: 0.4 recall: 0.022535211267605635\n",
      "treshold: 0.8 precision: 0.7 recall: 0.01971830985915493\n",
      "treshold: 0.8500000000000001 precision: 0.6 recall: 0.008450704225352112\n",
      "treshold: 0.9 precision: 1.0 recall: 0.0028169014084507044\n",
      "treshold: 0.9500000000000001 precision: nan recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anirogozina/Documents/gitlab/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for treshold in np.arange(0, 1, 0.05):\n",
    "    tp = ((targets == 1) & (predictions > treshold )).sum()\n",
    "    fp = ((targets == 0) & (predictions > treshold)).sum()\n",
    "    tn = ((targets == 0) & (predictions < treshold )).sum()\n",
    "    fn = ((targets == 1) & (predictions < treshold )).sum()\n",
    "    print('treshold:', treshold, 'precision:',  tp/(tp + fp), 'recall:',  tp/(tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gitlab",
   "language": "python",
   "name": "gitlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
